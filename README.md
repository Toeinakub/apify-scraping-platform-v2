# Apify Scraping Platform - Prototype

A modern web scraping platform prototype built with Next.js, featuring AI-powered lead intelligence and social listening capabilities.

## ğŸ¯ Overview

This is a **prototype/mockup** demonstrating a scraping platform UI/UX for:
- Lead opportunity discovery
- Social media listening
- Data analytics and visualization
- Session management

## ğŸ› ï¸ Tech Stack

- **Framework:** Next.js 15 (App Router)
- **Language:** TypeScript
- **Styling:** Tailwind CSS
- **UI Components:** shadcn/ui
- **Database:** Prisma (PostgreSQL)
- **Deployment:** Vercel

## ğŸ“‚ Project Structure

```
apify-scraping-platform-v2/
â”œâ”€â”€ app/                      # Next.js app router pages
â”‚   â”œâ”€â”€ analytics/           # Analytics dashboard
â”‚   â”œâ”€â”€ dashboard/           # Main dashboard
â”‚   â”œâ”€â”€ sessions/            # Session management
â”‚   â”œâ”€â”€ scrape/              # Scraping interface
â”‚   â””â”€â”€ mock/                # Mock/prototype pages
â”œâ”€â”€ components/              # React components
â”‚   â”œâ”€â”€ analytics/          # Analytics components
â”‚   â”œâ”€â”€ dashboard/          # Dashboard components
â”‚   â”œâ”€â”€ sessions/           # Session components
â”‚   â””â”€â”€ ui/                 # shadcn/ui components
â”œâ”€â”€ lib/                    # Utilities and helpers
â”‚   â”œâ”€â”€ apify/             # Apify client utilities
â”‚   â”œâ”€â”€ db/                # Database queries
â”‚   â””â”€â”€ utils/             # Helper functions
â””â”€â”€ types/                 # TypeScript type definitions
```

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+ 
- npm or yarn
- PostgreSQL database (or Supabase account)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Toeinakub/apify-scraping-platform-v2.git
cd apify-scraping-platform-v2
```

2. Install dependencies:
```bash
npm install
```

3. Set up environment variables:
```bash
cp .env.example .env.local
```

Edit `.env.local` with your credentials:
```env
DATABASE_URL="your-database-url"
APIFY_API_TOKEN="your-apify-token"
OPENAI_API_KEY="your-openai-key"
```

4. Run database migrations:
```bash
npx prisma migrate dev
```

5. Start the development server:
```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“¦ Features

### âœ¨ Implemented (Prototype)
- âœ… Modern dashboard UI
- âœ… Analytics visualization
- âœ… Session management interface
- âœ… Scraping form mockups
- âœ… Data table components
- âœ… Dark mode support
- âœ… Responsive design

### ğŸš§ In Development
- â³ Real-time scraping integration
- â³ AI-powered data classification
- â³ Advanced filtering and search
- â³ Export functionality
- â³ User authentication

## ğŸ¨ Design System

This project uses a custom design system built with:
- **Colors:** HSL-based color palette with dark mode support
- **Typography:** Inter font family
- **Components:** shadcn/ui component library
- **Animations:** Framer Motion for smooth transitions

## ğŸ“ Scripts

```bash
npm run dev          # Start development server
npm run build        # Build for production
npm run start        # Start production server
npm run lint         # Run ESLint
```

## ğŸ”’ Security

âš ï¸ **Important:** Never commit sensitive data to the repository:
- API keys
- Database credentials
- Authentication tokens

All sensitive data should be stored in `.env.local` (which is gitignored).

## ğŸ“„ License

This is a prototype project for demonstration purposes.

## ğŸ¤ Contributing

This is a prototype/mockup project. For questions or suggestions, please open an issue.

---

**Live Demo:** [https://apify-scraping-platform-v2.vercel.app](https://apify-scraping-platform-v2.vercel.app)

**Built with â¤ï¸ using Next.js and shadcn/ui**
